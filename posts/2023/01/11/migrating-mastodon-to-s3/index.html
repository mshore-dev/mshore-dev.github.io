<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Migrating Mastodon to S3 | Michael's Blog</title><meta name=keywords content="mastodon,self-hosting"><meta name=description content="Forewarning I made some mistakes, and those mistakes cost me fair bit of time. This is not a guide! This is my experiences migrating from local file storage to a cloud provider, and the issues and solution I came across along the way. At the end of the post, I have linked a few guides relating to this topic, refer to those for your how-to guides. With that out of the way, let us begin."><meta name=author content><link rel=canonical href=https://mshore-dev.github.io/posts/2023/01/11/migrating-mastodon-to-s3/><link crossorigin=anonymous href=/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://mshore-dev.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://mshore-dev.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mshore-dev.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://mshore-dev.github.io/apple-touch-icon.png><link rel=mask-icon href=https://mshore-dev.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Migrating Mastodon to S3"><meta property="og:description" content="Forewarning I made some mistakes, and those mistakes cost me fair bit of time. This is not a guide! This is my experiences migrating from local file storage to a cloud provider, and the issues and solution I came across along the way. At the end of the post, I have linked a few guides relating to this topic, refer to those for your how-to guides. With that out of the way, let us begin."><meta property="og:type" content="article"><meta property="og:url" content="https://mshore-dev.github.io/posts/2023/01/11/migrating-mastodon-to-s3/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-11T23:29:01-05:00"><meta property="article:modified_time" content="2023-01-11T23:29:01-05:00"><meta property="og:site_name" content="Michael's Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Migrating Mastodon to S3"><meta name=twitter:description content="Forewarning I made some mistakes, and those mistakes cost me fair bit of time. This is not a guide! This is my experiences migrating from local file storage to a cloud provider, and the issues and solution I came across along the way. At the end of the post, I have linked a few guides relating to this topic, refer to those for your how-to guides. With that out of the way, let us begin."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://mshore-dev.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Migrating Mastodon to S3","item":"https://mshore-dev.github.io/posts/2023/01/11/migrating-mastodon-to-s3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Migrating Mastodon to S3","name":"Migrating Mastodon to S3","description":"Forewarning I made some mistakes, and those mistakes cost me fair bit of time. This is not a guide! This is my experiences migrating from local file storage to a cloud provider, and the issues and solution I came across along the way. At the end of the post, I have linked a few guides relating to this topic, refer to those for your how-to guides. With that out of the way, let us begin.","keywords":["mastodon","self-hosting"],"articleBody":"Forewarning I made some mistakes, and those mistakes cost me fair bit of time. This is not a guide! This is my experiences migrating from local file storage to a cloud provider, and the issues and solution I came across along the way. At the end of the post, I have linked a few guides relating to this topic, refer to those for your how-to guides. With that out of the way, let us begin.\nThe problem A few days ago, I set up a Mastodon server. It is not a large server by any means, with me and a few friends being the only registered users. However, the process of federating with a (relatively large amount!) of external servers has generated a lot of cached data - avatars, headers, and toot attachments. In the three days my instance has been running, Mastodon has cached just over 30GB of media.\nmike@nonbiri:~$ du -s -h mastodon/mastodon/system/ 33G mastodon/mastodon/system/ mike@nonbiri:~$ df -h / Filesystem Size Used Avail Use% Mounted on /dev/vda1 59G 42G 14G 76% / When initially setting up Mastodon, I severely underestimated the amount of data that would be cached. Surely with only three users, it would be a manageable amount. After all, I had 60GB of storage to play with. Had I not connected my instance to a few relays, this may have been the case. However, adding relays allowed my server to see a much larger portion of the fediverse. This came at the cost of longer Sidekiq queues and - you guessed it! - drastically more media being cached.\nThe solution I could disconnect my instance from relays, but that would defeat the purpose of being connected to the fediverse. Instead, I opted to relieve my VPS of media serving duties and use a cloud service to store and serve media. There are many cloud storage providers to choose from, each with their pros and cons. A popular choice seems to be iDrive E2, however I have decided to go with a more standard option - Backblaze B2. Additionally, I’ll be adding a CDN (Bunny.net) in order to use a custom domain name (media.my-mastodon.tld) and improve loading times for other instances.\nMigrating There are plenty of wonderful guides on migrating Mastodon to cloud storage123 - this will be an abridged version of these with some of my own experience tossed in. The general outline for migrating storage is as follows:\nPrune current cache to a reasonable size Move existing data to cloud storage Configure Mastodon to use cloud storage Do one final copy to get any new media created after 2, but before 3 For my instance, pruning “old” media is not particularly helpful, as the instance itself has been running for less than 3 days. So for this migration, I will be skipping over this step. Which leads us to…\nMoving existing data Easy enough, create a bucket on Backblaze, generate an application key for rclone and start transferring. First, it is important to do a “dry run” to ensure the files will end up in the right place. It is much easier to ls twice and cp once, rather than re-organizing the files afterwords.\nmike@nonbiri:~/mastodon/mastodon$ rclone copy system/ b2: --dry-run 2023/01/08 19:19:21 NOTICE: media_attachments/thumbnails/109/654/680/682/023/877/original/5df0b7e9ccd26181.png: Skipped copy as --dry-run is set 2023/01/08 19:19:21 NOTICE: media_attachments/thumbnails/109/654/756/060/845/646/original/bd2fc4ad731afd8a.png: Skipped copy as --dry-run is set 2023/01/08 19:19:21 NOTICE: media_attachments/thumbnails/109/644/732/253/007/928/original/4d46805fd057033a.jpg: Skipped copy as --dry-run is set 2023/01/08 19:19:21 NOTICE: media_attachments/thumbnails/109/639/809/444/715/946/original/ab38a20af8bf6518.png: Skipped copy as --dry-run is set Initially, I was unsure if I was just supposed to copy the contents of mastodon/system/ to cloud storage, but after confirming the naming schemes on other Mastodon instances it seems to be correct. Now that we have verified the destination of the data, we can let rclone rip.\nHere is where we run into our first issue. We already established that mastodon/system/ was 33GB, but the cache folder made up 99% of that. rclone ran, copying data for 20 minutes, and only made it through the first ~4000 files, totallying ~1.5GB. All of these files being cached media. Since the instance was brand-new, there was not yet much local media. Instead of attempting to transfer all of the current cache to B2, I opted to leave the cache behind and only copy the accounts and media_attachments folders. Once again, ls twice and cp once, so after verifying the command was correct, I started copying the accounts folder.\nThis resulted in 38 files being copied.\nSetting up Bunny.net To set up Bunny CDN, I followed their official guide for using Bunny CDN with Backblaze B2. Afterwords, I added a custom domain by creating a CNAME record at my domain registrar, as shown in their guide for setting up a custom subdomain.\nConfiguring Mastodon After copying the important files over and setting up Bunny, it was time to configure Mastodon to use B2 and Bunny. As outlined in these wonderful guides123, it should be as simple as changing a few environment variables and restarting Mastodon. Since I deployed Mastodon using Docker Compose, I added the following lines to the the web, streaming and sidekiq containers:\nenvironment: S3_ENABLED: \"true\" S3_BUCKET: \"${MASTODON_S3_BUCKET}\" S3_HOSTNAME: \"media.${MASTODON_DOMAIN}\" AWS_ACCESS_KEY_ID: \"${MASTODON_S3_KEY_ID}\" AWS_SECRET_ACCESS_KEY: \"${MASTODON_S3_SECRET_KEY}\" S3_PROTOCOL: \"https\" S3_ENDPOINT: \"${MASTODON_S3_ENDPOINT}\" (The secret values are stored in a .env file)\nIn theory, this should grant us a working Mastodon instance, serving files on cloud storage, behind a CDN. With a great deal of trepidation, I restarted the Mastodon containers…\nSurprisingly enough, it almost worked.\nI made a small error while copy the files (or configuring Mastodon, not entirely sure) but Mastodon was trying to serve files from a sub-directory on B2, which did not have the uploaded files. After moving the files into the correct place:\nmike@nonbiri:~$ rclone copy b2:nonbiri-social/accounts/ b2:nonbiri-social/nonbiri-social/accounts/ mike@nonbiri:~$ rclone copy b2:nonbiri-social/media_attachments/ b2:nonbiri-social/nonbiri-social/media_attachments/ Local user media was back! New media was also stored correctly! However, old content from other instances would not load. In all honesty, I had anticipated running into this problem, but hoped nevertheless hoped I would get lucky. Fortunately, tootctl has a function to clear the local media cache:\nmike@nonbiri:~/mastodon$ ./tootctl.sh media remove --days 0 22653/22653 |===============================================================================| Time: 00:13:52 Removed 22653 media attachments (approx. 24.3 GB) This would, unfortunately, mean Mastodon would have to re-download (and in this case, re-upload) remote media files. Removing the 22.6K media files took around 12 minutes.\nAlas, this did not bring back old remote media either. In the end, I was unable to force Mastodon to immediately re-download the missing media. In an attempt to restore the missing avatars and headers, I set the media retention times to one day, and let the instance run as normal for a few days. Sadly, this did not bring back the avatars/headers either.\nAfter further research, I came across this issue on mastodon/mastodon GitHub which suggests that “media” refers only to content attached to posts, not avatars and headers. This issue recommends tootctl account refresh --all as the equivalent for re-downloading the data I am missing. While this seems like it would solve my issue, I had a few concerns about the time and bandwidth costs of fetching the information of the 20K accounts my instance knows of.\nmike@nonbiri:~/mastodon$ ./tootctl.sh account refresh --all --dry-run 20223/20234 |============================================================================== | ETA: ??:??:?? Refreshed 20234 accounts (DRY RUN) Reluctantly, I opened a new tmux session and let it run. The estimated time for completion started at just over three hours. It was doing a bit more work than I needed it to, but it appears to be the only solution to fix all of the missing avatars/headers in one go. After about 4 hours, all of the accounts were finally refreshed:\nmike@nonbiri:~/mastodon$ ./tootctl.sh accounts refresh --all Refreshed 20590 accounts Just like that, all of the missing avatars and headers were back!\nConclusion Overall, this migration went… Yeah, it went. Had I been more diligent, perhaps I could have avoided these issues. But I am glad to have run into them now, rather than down the road. In the end, everything worked fine and it was a great learning experience.\nFuture Goals My main reason for setting up a Mastodon instance is to learn more about systems administration and the fediverse. In the future, I would like to deploy a scaled-up, public Mastodon instance. To work towards that goal, I decided to start on a smaller scale, and iron out some kinks ahead of time.\nWith that said, the next subject I would like to investigate is a proper backup solution.\nSome additional topics I would like to investigate further down the road:\nAdding more Sidekiq workers to aid in scaling Self-hosting Minio to serve media Mastodon forks: glitch-soc and Hometown Other resources https://stanislas.blog/2018/05/moving-mastodon-media-files-to-wasabi-object-storage/ ↩︎ ↩︎\nhttps://github.com/cybrespace/cybrespace-meta/blob/master/s3.md ↩︎ ↩︎\nhttps://maciej.lasyk.info/2023/Jan/08/migrating-mastodon-storage-to-s3-compatible/ ↩︎ ↩︎\n","wordCount":"1444","inLanguage":"en","datePublished":"2023-01-11T23:29:01-05:00","dateModified":"2023-01-11T23:29:01-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mshore-dev.github.io/posts/2023/01/11/migrating-mastodon-to-s3/"},"publisher":{"@type":"Organization","name":"Michael's Blog","logo":{"@type":"ImageObject","url":"https://mshore-dev.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mshore-dev.github.io/ accesskey=h title="Michael's Blog (Alt + H)">Michael's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Migrating Mastodon to S3</h1><div class=post-meta><span title='2023-01-11 23:29:01 -0500 -0500'>January 11, 2023</span></div></header><div class=post-content><h2 id=forewarning>Forewarning<a hidden class=anchor aria-hidden=true href=#forewarning>#</a></h2><p>I made some mistakes, and those mistakes cost me fair bit of time. This is <em>not</em> a guide! This is my experiences migrating from local file storage to a cloud provider, and the issues and solution I came across along the way. At the end of the post, I have linked a few guides relating to this topic, refer to those for your how-to guides. With that out of the way, let us begin.</p><h2 id=the-problem>The problem<a hidden class=anchor aria-hidden=true href=#the-problem>#</a></h2><p>A few days ago, I set up a Mastodon server. It is not a large server by any means, with me and a few friends being the only registered users. However, the process of federating with a (relatively large amount!) of external servers has generated a lot of cached data - avatars, headers, and toot attachments. In the three days my instance has been running, Mastodon has cached just over 30GB of media.</p><pre tabindex=0><code>mike@nonbiri:~$ du -s -h mastodon/mastodon/system/
33G     mastodon/mastodon/system/
mike@nonbiri:~$ df -h /
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda1        59G   42G   14G  76% /
</code></pre><p>When initially setting up Mastodon, I severely underestimated the amount of data that would be cached. Surely with only three users, it would be a manageable amount. After all, I had 60GB of storage to play with. Had I not connected my instance to a few relays, this may have been the case. However, adding relays allowed my server to see a much larger portion of the fediverse. This came at the cost of longer Sidekiq queues and - you guessed it! - drastically more media being cached.</p><h2 id=the-solution>The solution<a hidden class=anchor aria-hidden=true href=#the-solution>#</a></h2><p>I could disconnect my instance from relays, but that would defeat the purpose of being connected to the fediverse. Instead, I opted to relieve my VPS of media serving duties and use a cloud service to store and serve media. There are many cloud storage providers to choose from, each with their pros and cons. A popular choice seems to be <a href=https://www.idrive.com/e2/>iDrive E2</a>, however I have decided to go with a more standard option - <a href=https://www.backblaze.com/b2/cloud-storage.html>Backblaze B2</a>. Additionally, I&rsquo;ll be adding a CDN (<a href=https://bunny.net>Bunny.net</a>) in order to use a custom domain name (media.my-mastodon.tld) and improve loading times for other instances.</p><h2 id=migrating>Migrating<a hidden class=anchor aria-hidden=true href=#migrating>#</a></h2><p>There are plenty of wonderful guides on migrating Mastodon to cloud storage<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> - this will be an abridged version of these with some of my own experience tossed in. The general outline for migrating storage is as follows:</p><ol><li>Prune current cache to a reasonable size</li><li>Move existing data to cloud storage</li><li>Configure Mastodon to use cloud storage</li><li>Do one final copy to get any new media created after 2, but before 3</li></ol><p>For my instance, pruning &ldquo;old&rdquo; media is not particularly helpful, as the instance itself has been running for less than 3 days. So for this migration, I will be skipping over this step. Which leads us to&mldr;</p><h2 id=moving-existing-data>Moving existing data<a hidden class=anchor aria-hidden=true href=#moving-existing-data>#</a></h2><p>Easy enough, create a bucket on Backblaze, generate an application key for rclone and start transferring. First, it is important to do a &ldquo;dry run&rdquo; to ensure the files will end up in the right place. It is much easier to <code>ls</code> twice and <code>cp</code> once, rather than re-organizing the files afterwords.</p><pre tabindex=0><code>mike@nonbiri:~/mastodon/mastodon$ rclone copy system/ b2: --dry-run
2023/01/08 19:19:21 NOTICE: media_attachments/thumbnails/109/654/680/682/023/877/original/5df0b7e9ccd26181.png: Skipped copy as --dry-run is set
2023/01/08 19:19:21 NOTICE: media_attachments/thumbnails/109/654/756/060/845/646/original/bd2fc4ad731afd8a.png: Skipped copy as --dry-run is set
2023/01/08 19:19:21 NOTICE: media_attachments/thumbnails/109/644/732/253/007/928/original/4d46805fd057033a.jpg: Skipped copy as --dry-run is set
2023/01/08 19:19:21 NOTICE: media_attachments/thumbnails/109/639/809/444/715/946/original/ab38a20af8bf6518.png: Skipped copy as --dry-run is set
&lt;snip&gt;
</code></pre><p>Initially, I was unsure if I was just supposed to copy the contents of <code>mastodon/system/</code> to cloud storage, but after confirming the naming schemes on other Mastodon instances it seems to be correct. Now that we have verified the destination of the data, we can let <code>rclone</code> rip.</p><p>Here is where we run into our first issue. We already established that <code>mastodon/system/</code> was 33GB, but the <code>cache</code> folder made up 99% of that. <code>rclone</code> ran, copying data for 20 minutes, and only made it through the first ~4000 files, totallying ~1.5GB. All of these files being cached media. Since the instance was brand-new, there was not yet much local media. Instead of attempting to transfer all of the current cache to B2, I opted to leave the cache behind and only copy the <code>accounts</code> and <code>media_attachments</code> folders. Once again, <code>ls</code> twice and <code>cp</code> once, so after verifying the command was correct, I started copying the <code>accounts</code> folder.</p><p>This resulted in 38 files being copied.</p><h2 id=setting-up-bunnynet>Setting up Bunny.net<a hidden class=anchor aria-hidden=true href=#setting-up-bunnynet>#</a></h2><p>To set up Bunny CDN, I followed <a href=https://support.bunny.net/hc/en-us/articles/360018649972-How-to-speed-up-your-BackBlaze-B2-file-delivery-with-BunnyCDN>their official guide for using Bunny CDN with Backblaze B2</a>. Afterwords, I added a custom domain by creating a CNAME record at my domain registrar, as shown in <a href=https://support.bunny.net/hc/en-us/articles/207790279-How-to-set-up-a-custom-CDN-hostname>their guide for setting up a custom subdomain</a>.</p><h2 id=configuring-mastodon>Configuring Mastodon<a hidden class=anchor aria-hidden=true href=#configuring-mastodon>#</a></h2><p>After copying the important files over and setting up Bunny, it was time to configure Mastodon to use B2 and Bunny. As outlined in these wonderful guides<sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup><sup id=fnref1:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup><sup id=fnref1:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, it should be as simple as changing a few environment variables and restarting Mastodon. Since I deployed Mastodon using Docker Compose, I added the following lines to the the web, streaming and sidekiq containers:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>environment</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>S3_ENABLED</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>S3_BUCKET</span>: <span style=color:#e6db74>&#34;${MASTODON_S3_BUCKET}&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>S3_HOSTNAME</span>: <span style=color:#e6db74>&#34;media.${MASTODON_DOMAIN}&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>AWS_ACCESS_KEY_ID</span>: <span style=color:#e6db74>&#34;${MASTODON_S3_KEY_ID}&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>AWS_SECRET_ACCESS_KEY</span>: <span style=color:#e6db74>&#34;${MASTODON_S3_SECRET_KEY}&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>S3_PROTOCOL</span>: <span style=color:#e6db74>&#34;https&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>S3_ENDPOINT</span>: <span style=color:#e6db74>&#34;${MASTODON_S3_ENDPOINT}&#34;</span>
</span></span></code></pre></div><p>(The secret values are stored in a <code>.env</code> file)</p><p>In theory, this should grant us a working Mastodon instance, serving files on cloud storage, behind a CDN. With a great deal of trepidation, I restarted the Mastodon containers&mldr;</p><p>Surprisingly enough, it <em>almost</em> worked.</p><p>I made a small error while copy the files (or configuring Mastodon, not entirely sure) but Mastodon was trying to serve files from a sub-directory on B2, which did not have the uploaded files. After moving the files into the correct place:</p><pre tabindex=0><code>mike@nonbiri:~$ rclone copy b2:nonbiri-social/accounts/ b2:nonbiri-social/nonbiri-social/accounts/
mike@nonbiri:~$ rclone copy b2:nonbiri-social/media_attachments/ b2:nonbiri-social/nonbiri-social/media_attachments/
</code></pre><p>Local user media was back! New media was also stored correctly! However, old content from other instances would not load. In all honesty, I had anticipated running into this problem, but hoped nevertheless hoped I would get lucky. Fortunately, <code>tootctl</code> has a function to clear the local media cache:</p><pre tabindex=0><code>mike@nonbiri:~/mastodon$ ./tootctl.sh media remove --days 0
22653/22653 |===============================================================================| Time: 00:13:52
Removed 22653 media attachments (approx. 24.3 GB)
</code></pre><p>This would, unfortunately, mean Mastodon would have to re-download (and in this case, re-upload) remote media files. Removing the 22.6K media files took around 12 minutes.</p><p>Alas, this did not bring back old remote media either. In the end, I was unable to force Mastodon to immediately re-download the missing media. In an attempt to restore the missing avatars and headers, I set the media retention times to one day, and let the instance run as normal for a few days. Sadly, this did not bring back the avatars/headers either.</p><p>After further research, I came across <a href=https://github.com/mastodon/mastodon/issues/9657>this issue on mastodon/mastodon GitHub</a> which suggests that &ldquo;media&rdquo; refers only to content attached to posts, not avatars and headers. This issue recommends <code>tootctl account refresh --all</code> as the equivalent for re-downloading the data I am missing. While this seems like it would solve my issue, I had a few concerns about the time and bandwidth costs of fetching the information of the 20K accounts my instance knows of.</p><pre tabindex=0><code>mike@nonbiri:~/mastodon$ ./tootctl.sh account refresh --all --dry-run
20223/20234 |============================================================================== |  ETA: ??:??:??
Refreshed 20234 accounts (DRY RUN)
</code></pre><p>Reluctantly, I opened a new <code>tmux</code> session and let it run. The estimated time for completion started at just over three hours. It was doing a bit more work than I needed it to, but it appears to be the only solution to fix <em>all</em> of the missing avatars/headers in one go. After about 4 hours, all of the accounts were finally refreshed:</p><pre tabindex=0><code>mike@nonbiri:~/mastodon$ ./tootctl.sh accounts refresh --all
&lt;snip&gt;
Refreshed 20590 accounts
</code></pre><p>Just like that, all of the missing avatars and headers were back!</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Overall, this migration went&mldr; Yeah, it went. Had I been more diligent, perhaps I could have avoided these issues. But I am glad to have run into them now, rather than down the road. In the end, everything worked fine and it was a great learning experience.</p><h2 id=future-goals>Future Goals<a hidden class=anchor aria-hidden=true href=#future-goals>#</a></h2><p>My main reason for setting up a Mastodon instance is to learn more about systems administration and the fediverse. In the future, I would like to deploy a scaled-up, public Mastodon instance. To work towards that goal, I decided to start on a smaller scale, and iron out some kinks ahead of time.</p><p>With that said, the next subject I would like to investigate is a proper backup solution.</p><p>Some additional topics I would like to investigate further down the road:</p><ul><li>Adding more Sidekiq workers to aid in scaling</li><li>Self-hosting <a href=https://github.com/minio/minio>Minio</a> to serve media</li><li>Mastodon forks: <a href=https://github.com/glitch-soc/mastodon>glitch-soc</a> and <a href=https://github.com/hometown-fork/hometown>Hometown</a></li></ul><h3 id=other-resources>Other resources<a hidden class=anchor aria-hidden=true href=#other-resources>#</a></h3><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://stanislas.blog/2018/05/moving-mastodon-media-files-to-wasabi-object-storage/>https://stanislas.blog/2018/05/moving-mastodon-media-files-to-wasabi-object-storage/</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://github.com/cybrespace/cybrespace-meta/blob/master/s3.md>https://github.com/cybrespace/cybrespace-meta/blob/master/s3.md</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://maciej.lasyk.info/2023/Jan/08/migrating-mastodon-storage-to-s3-compatible/>https://maciej.lasyk.info/2023/Jan/08/migrating-mastodon-storage-to-s3-compatible/</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://mshore-dev.github.io/tags/mastodon/>mastodon</a></li><li><a href=https://mshore-dev.github.io/tags/self-hosting/>self-hosting</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://mshore-dev.github.io/>Michael's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>